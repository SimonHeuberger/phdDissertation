# CONCLUSION {#conclusion}

Education is one of the most important predictors of political behavior in political science. As an ordinal variable, education possesses special characteristics: Its categories are ordered, but unevenly spaced. It is crucial that we try to use this unique information to the greatest extent possible. If we want to know what people think and how they act, we need to make sure our measurements are as good as they can possibly be. The ordered probit approach I outlined and applied in the previous chapters represents an attempt to do so. While there are some encouraging signs, the overall conclusion after these analyses speaks against an endorsement of this approach. Assuming a latent underlying continuous variable underneath education, estimating cutoff thresholds between the education categories, and binning observations according to linear model predictors to obtain a new set of education categories based on data fit overall does not appear to improve upon current research practice. 

Blocking on the two differing education sets (ANES and OP) shows mixed results. While an ANOVA regression of the numerical variables does not result in statistically distinct intercepts, a similar general linear model reveals statistical significance for most of the factor variables. The distributions of the placebo regression treatment variables appear to indicate slightly superior performance by the OP method, but this evidence is tentative because of the sample size. It is thus overall unclear whether the re-estimation of ordinal variable categories with an ordered probit approach matters for the process of blocking.

The verdict is much clearer for multiple hot deck imputation with ordinal variables. Adapting the multiple hot deck imputation function `hot.deck` to treat ordinal variables with an ordered probit model does not improve on current methods. `hd.ord` performs on par with some binary variables but worse than `amelia` and `mice` for interval and ordinal variables. This applies for all mechanisms of missingness, differing numbers of variables with missing values, differing numbers of ordinal variables included in the `polr` treatment, and differing percentages of missingness. A cautious exception might be claimed for data MNAR based on the framing analysis in chapter \ref{framing}, where `hd.ord` performed on par with `amelia` for binary variables. Since the aim was to develop a method that improves upon current approaches rather than merely matching their performance, however, this does not change the overall conclusions. `hd.ord`'s gains in imputation speed do not make up for these shortcomings either. While it is necessary to iterate multiple imputation runs many times over for simulation purposes, users likely will not do so, which greatly diminishes the computing time saved. The result of the quality comparison of major missing data solutions is thus a clear endorsement of `amelia`. 

The methodological results from the online survey experiment on political framing do not show substantive differences. The results obtained from the analysis of the ANES education set do not differ from those for the OP set. Estimating and distinguishing between these two sets of categories does not affect the substantive results regarding morality and self-interest. The missing data analysis confirms the superiority of `amelia`. The substantive results on political framing themselves are mixed. There is evidence that `Moral Opposing` frames move people more towards opposing the issue policies than `Self-Interest Opposing` frames, but the same does not hold true for `Moral Supporting` frames. Similarly, `Moral Opposing` frames do appear to resonate more strongly with respondents with high morality scores, but `Moral Supporting` frames do not. There is no evidence that self-interest frames move people with higher self-interest scores more than people with lower self-interest scores. 

Overall, evidence suggests that the re-estimation and distinction of education categories does not matter. The mixed findings in chapter \ref{ordblock} are outweighed by the clear results from chapters \ref{ordmiss} and \ref{framing}. While the ordered probit re-estimation based on an assumed underlying continuous variable does not appear to be important, however, doubts remain about the need for the overall large number of education categories in the ANES. These finely grated and overly nuanced categories often result in a low number of observations per category, which in turn renders ordinal logistic regression difficult, greatly increases regression coefficients, and makes model estimation cumbersome. The large number also leads to frequent collinearity, causing regression models to drop variable levels. None of this occurs with the OP education categories, of which there are a lot fewer. With a lower number of ANES categories, these problems might not appear.

It is never fun to find out that a developed method does not work, and I naturally hoped for a different outcome. My endeavors have nonetheless not been fruitless. We have learned that a focus on ordinal variables is of minor importance for missing data imputation and that `amelia`'s combination of expectation-maximization with bootstrapping is robust and provides outstanding results for all types of variables in a variety of missing data scenarios. We have also learned that morality at least plays a role in frame strength regarding the things we oppose. These represent important findings on the continuing journey to advance, refine, and conduct public opinion measurement.

<!--
Most importantly, however, we have learned that the current practice of converting ordinal explanatory variables into numerical variables does not seem to be problematic after all, as this convenience method appears to closely reflect the true underlying data structure. 
We need modern statistical methods to fully utilize all this information contained in this variable. So far, this aspect has been largely ignored in the literature. 
Whether my methods are suitable in a specific survey or survey experiment depends on the situation, as no method works for all circumstances. 
For a survey experiment with a very large sample and few treatment groups, there is no need for blocking. Simple randomization does the job here. Similarly, if survey results do not contain important ordinal predictor variables, there is no need for a method specifically geared towards ordinal variables. 
Overall, my dissertation adds two important new tools to the empirical political scientist's toolbox to choose from.
-->



