# CONCLUSION {#conclusion}

Education is one of the most important predictors of political behavior in political science. As an ordinal variable, education possesses special characteristics: Its categories are ordered, but unevenly spaced. It is crucial that we try to use this unique information to the greatest extent possible. If we want to know what people think and how they act, we need to make sure our measurements are as good as they can possibly be. The ordered probit approach I outlined and applied in the previous chapters represents an attempt to do so. \textcolor{red}{While there are some encouraging signs, the overall results do not show the improvement in performance I was aiming for. Assuming a latent underlying continuous variable underneath education, estimating cutoff thresholds between the education categories, and binning observations according to linear model predictors to obtain a new set of education categories based on data fit provides promising results in some areas but overall does not improve upon current research practice on the scale I had envisioned.}

\textcolor{red}{Blocking on the two differing education sets (ANES and OP) shows promising if mixed results. While an ANOVA regression of the numerical variables does not result in statistically distinct intercepts, a similar general linear model reveals statistical significance for most of the factor variables. The distributions of the placebo regression treatment variables appear to indicate slightly superior performance by the OP method. Re-estimating ordinal variable categories with an ordered probit approach for the process of blocking appears to matter for factor variables with a low number of unique categories, but not for numerical variables with a high number of unique values.}

\textcolor{red}{The verdict is clearer for multiple hot deck imputation with ordinal variables: Adapting the multiple hot deck imputation function `hot.deck` to treat ordinal variables with an ordered probit model overall does not improve on current methods. `hd.ord` performs worse than `amelia` and `mice` for interval and ordinal variables for all mechanisms of missingness, differing numbers of variables with missing values, differing numbers of ordinal variables included in the `polr` treatment, and differing percentages of missingness. `hd.ord` also shows inferior results for binary variable in data MAR. For binary variables in data MNAR, however, `hd.ord` performs on par with `amelia` and `mice`. `hd.ord` also computes imputations significantly faster than the other methods. Since most basic users conduct single runs of multiple imputation, this gain has somewhat reduced practical relevance. For specific circumstances such as Bayesian analysis with a large number of simulations, though, `hd.ord` can save valuable computing time and resources.}

The methodological results from the online survey experiment on political framing do not show substantive differences. The results obtained from the analysis of the ANES education set do not differ from those for the OP set. Estimating and distinguishing between these two sets of categories does not affect the substantive results regarding morality and self-interest. \textcolor{red}{The missing data analysis confirms the superiority of `amelia` overall but also repeats `hd.ord`'s equivalent performance for binary variables when data are MNAR.} The substantive results on political framing themselves are mixed. There is evidence that `Moral Opposing` frames move people more towards opposing the issue policies than `Self-Interest Opposing` frames, but the same does not hold true for `Moral Supporting` frames. Similarly, `Moral Opposing` frames do appear to resonate more strongly with respondents with high morality scores, but `Moral Supporting` frames do not. There is no evidence that self-interest frames move people with higher self-interest scores more than people with lower self-interest scores. 

\textcolor{red}{Overall, evidence suggests that the re-estimation and distinction of education categories overall does not matter as much as I had envisioned. The findings in chapter \ref{ordblock} show positive signs but are outweighed by the results in chapters \ref{ordmiss} and \ref{framing}. The ordinal probit approach does not improve on handling missing data overall and does not result in substantive differences when used for blocking with original data from an online survey experiment on political framing. For specific circumstances, however, it might nonetheless be the method of choice when blocking and imputing missing data. The OP approach shows statistically significant intercepts for almost all factor variables after blocking and `hd.ord` performs as well as `amelia` for binary variables in data MNAR and provides a significant speed gain for analyses that involve a large number of simulations. These findings clearly point to a need for further exploration to get us to a point where we might have a good diagnostic test for when we should assume the ordinal categories might map well to a latent variable and when they might not. Developing such a test would be crucial to identify why the mapping of the latent variable works well in these specific circumstances but not in most others.}

\textcolor{red}{The outcome does not possess the transforming impact I had hoped for, but my endeavors have nonetheless been far from fruitless. We have learned that blocking with the OP approach results in significant differences for factor variables and that it provides advantages over other methods for the imputation of missing data in specific circumstances. We have also learned that morality plays a role in frame strength regarding the things we oppose. These represent important findings on the continuing journey to advance, refine, and conduct public opinion measurement.}


<!--

Doubts remain about the need for the overall large number of education categories in the ANES. These finely grated and overly nuanced categories often result in a low number of observations per category, which in turn renders ordinal logistic regression difficult, greatly increases regression coefficients, and makes model estimation cumbersome. The large number also leads to frequent collinearity, causing regression models to drop variable levels. None of this occurs with the OP education categories, of which there are a lot fewer. With a lower number of ANES categories, these problems might not appear.

Most importantly, however, we have learned that the current practice of converting ordinal explanatory variables into numerical variables does not seem to be problematic after all, as this convenience method appears to closely reflect the true underlying data structure. 
We need modern statistical methods to fully utilize all this information contained in this variable. So far, this aspect has been largely ignored in the literature. 
Whether my methods are suitable in a specific survey or survey experiment depends on the situation, as no method works for all circumstances. 
For a survey experiment with a very large sample and few treatment groups, there is no need for blocking. Simple randomization does the job here. Similarly, if survey results do not contain important ordinal predictor variables, there is no need for a method specifically geared towards ordinal variables. 
Overall, my dissertation adds two important new tools to the empirical political scientist's toolbox to choose from.
-->



