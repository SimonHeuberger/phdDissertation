---
title: "Monte Carlo Simulation To Show That polr() Binning Matters "
date: "`r format(Sys.time(), '%d %B, %Y')`"
header-includes:
   - \usepackage{dcolumn}
output: pdf_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}

library(stargazer)
library(here)


#### The main idea here is showing that that the binning matters in the polr() sense ####

# Create a non-integer "education" threshold vector, called theta
# Make theta spaced out
# I decide what values theta takes
# These values represent the underlying truth in the simulation
theta <- c(-15.2, -10.4, -5.4, 0.9, 5.6, 10.9, 15.5)


# Create a rounded (i.e. integer) version of theta. This moves the cases around a bit
# theta is the truth. theta.star is 'wrong'
set.seed(134)
theta.star <- jitter(theta, 5)


# Create numeric "education" categories based on theta
categories <- as.numeric(1:(length(theta)+1)) # +1 to account for categories below minimum and above maximum of theta


# Create the "education" data based on theta and selected from a uniform distribution
# Use a number of observations that equals a reasonable number in survey experiments. I chose 1600 overall
# 1600 observations get split across the eight categories
# V and Z are to create observation below the minimum and above the maximum thresholds
# The cases resulting from the runif() are the true underlying data generation
V <- NULL
Y <- NULL 
Z <- NULL
set.seed(123)
obs <- 1600
obs.cat <- obs/length(categories)
V <- c(V, runif(obs.cat, theta[1]-2, theta[1]))
for (i in 1:(length(theta)-1)){     
  Y <- c(Y, runif(obs.cat, theta[i], theta[(i+1)])) 
  # uniform distribution with obs.cat observations, a minimum of one element of theta, and a maximum of the following element of theta
}
Z <- c(Z, runif(obs.cat, theta[length(theta)], theta[length(theta)]+2))
Y <- c(V,Y,Z)



## The following is from here: https://stat.ethz.ch/pipermail/r-help/2007-April/128925.html ##

X <- scale(matrix(rnorm(6*obs), ncol = 6))

YX <- cbind(scale(Y), X)

chol1 <- solve(chol(var(YX)))

new.YX <- YX %*% chol1

zapsmall(cor(new.YX))
all.equal(YX[,1], new.YX[,1])

cor.mat <- matrix(c(
    1,    .4,    -.4,    .3,    .3,    .5,   -.1,
   .4,     1,     .1,   -.5,    .2,     0,   -.2,
  -.4,    .1,      1,  -.25,   -.4,    .4,  -.15,
   .3,   -.5,   -.25,     1,   -.3,   .45,   .05,
   .3,    .2,    -.4,   -.3,     1,   -.3,    .4,
   .5,     0,     .4,   .45,   -.3,     1,   -.2,
  -.1,   -.2,   -.15,   .05,    .4,   -.2,     1),
  ncol = 7)

chol2 <- chol(cor.mat)
final.YX <- new.YX %*% chol2 * sd(Y) + mean (Y)
colnames(final.YX) <- c("Y", "X1", "X2", "X3", "X4", "X5", "X6")

mc.df <- data.frame(final.YX)





# Build an X matrix of covariates with correlations in-between the Xs and between the Xs and Y
# Take meaningful variables from the ANES and run a correlation matrix (cor()) on them. Make factor columns numeric for this to work. These are kind of 'typical' correlations we see in data. Use them as the correlations in-between the Xs
# Include Y when I create X, since I want a correlation between the Xs and Y as well
# It's kind of like what Jeff did here:
# X <- rpois(100,3) 
# Y <- 2*X + rnorm(100,0,0.25) 
# He created X and then created Y based on X. I just do it the other way round with additional correlations between the Xs
# This process is called random MVN (for two variables it would be bivariate generation)


# Bin the Y values into categories in two separate ways: (1) According to the theta thresholds, (2) according to the theta.star thresholds
temp.theta <- data.frame(matrix(NA, nrow(mc.df), length(categories))) # to store categories for observations binned with theta
temp.theta[,1] <- ifelse(mc.df$Y <= theta[1], categories[1], NA) # everything under minimum threshold
for(q in 1:(length(categories)-2)){ # everything between minimum and maximum thresholds
 temp.theta[,q+1] <- ifelse(mc.df$Y > theta[q] & mc.df$Y <= theta[q+1], categories[q+1], NA)
}
temp.theta[,length(categories)] <- ifelse(mc.df$Y > theta[length(theta)], categories[length(categories)], NA) # everything above maximum threshold

temp.theta.star <- data.frame(matrix(NA, nrow(mc.df), length(categories))) # same for theta.star
temp.theta.star[,1] <- ifelse(mc.df$Y <= theta.star[1], categories[1], NA)
for(q in 1:(length(categories)-2)){
 temp.theta.star[,q+1] <- ifelse(mc.df$Y > theta.star[q] & mc.df$Y <= theta.star[q+1], categories[q+1], NA)
}
temp.theta.star[,length(categories)] <- ifelse(mc.df$Y > theta.star[length(theta.star)], categories[length(categories)], NA)

mc.df <- subset(mc.df, select = -Y) # remove Y since we don't need it for the regression
mc.theta.star <- mc.theta <- mc.df # split mc.df into two versions (to make regression code simpler)
mc.theta[, "Y.theta"] <- c(na.omit(c(t(temp.theta)))) # assign binned theta categories to theta data frame
mc.theta.star[, "Y.theta.star"] <- c(na.omit(c(t(temp.theta.star)))) # assign binned theta.star categories to theta.star data frame

# Regress Y.theta and Y.theta.star separately
lm.theta <- lm(Y.theta ~., data = mc.theta) # ~. regresses on all remaining columns
lm.theta.star <- lm(Y.theta.star ~., data = mc.theta.star)
summary(lm.theta)
summary(lm.theta.star)

```


```{r results='asis', echo=FALSE}
stargazer(lm.theta, lm.theta.star,
          header = FALSE,
          title = "Importance of polr() binning",
          model.numbers = FALSE,
          no.space = TRUE,
          star.cutoffs = NA,
          omit.table.layout = "n",
          single.row = TRUE,
          align = TRUE)

```


