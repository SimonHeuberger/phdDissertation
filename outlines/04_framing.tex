\documentclass[12pt]{article}

\input{\string~"/Insync/templates/preamble2"}

\title{Framing}

\date{\today}

\begin{document}

\maketitle

%\section*{\st{Prospectus Revisions}}
%	\begin{coi}
%		\item \st{Ryan: Replace focus group with online MTurk. That can give me the same insights for a lot less money and effort}
%		\item \st{Proofread everything}
%	\end{coi}

%\section*{Pre-Polls}
%	\begin{coi}
%		\item I need to know how many pre-polls I'm running and how much money I should allocate for that (since it all needs to be within the Provost money)
%		\item I need to know that now because I need to tell Lucid how much much I'm paying them by mid-March
%		\item The current setup from the proposal is meta-analysis, three simple polls, experiment:
%			\begin{coi}
%				\item The meta-analysis gives me a list of all statistically significant frames
%				\item Poll \#1 asks respondents to rate how moral each argument in each of those frames is
%				\item Poll \#2 asks people what they consider moral arguments to be. I use the insights from poll \#2 to design frames for each of the `missing' frames in previous experiments (the idea being that no experiment so far has tested for positive/negative moral/amoral frames and there thus will be gaps)
%				\item Poll \#3 tests how moral/amoral my designed frames are
%				\item Then finally comes the survey experiment
%			\end{coi}
%		\item I have \$4,830. If I did one simple one for \$0.10 at 200 respondents, that would cost me \$28. So it would be \$84 for three simple polls with 200 respondents each, which leaves me with \$4,746. My R method online with Lucid costs \$2 each, so that would make 2,373 respondents for the experiment. That would leave 474 respondents per treatment group
%		\item Money-wise, that would work out. Now I need to know whether the proposal setup (meta-analysis, pre-polls) is feasible to do in a realistic time frame, with me teaching in both terms
%		\item Very good point from Ryan: He totally sees the point of polls 1 and 3, but not really poll 2. Removing 2 would obviously change the financial numbers -- but Rune Slothuus for instance said my idea for the open-ended poll about what makes frames moral is good
%		\item Jeff and Matt agree: Ditch poll \#2
%		\item Go with 300 respondents for each of the remaining pre-polls. To make sure people pay more attention to the frames, pay \$0.20 each. That comes out to \$168 for both pre-polls, which leaves \$4,662 for Lucid, which gives me 2,331 respondents, which means 466 respondents per treatment group
%	\end{coi}

\section*{General}
	\begin{coi}
		\item Design moral and unmoral frames and pretest both on MTurk, then use the `proven' frames for the survey experiment. This is a chapter on framing where I apply both methods in the experiment, analyze the methods' performances, and analyze the substantive results in terms of moral frames (the latter is where I produce/add some nuance in our understanding of framing)
		\item Using the experiment as the application for both papers
			\begin{coi}
				\item Paper I: One half of the sample gets the ordinal probit education categories, the other gets the original ones without giving respondents \texttt{Don't Know/Refuse} options. Compare the differences between the ordered probit and the original results whilst knowing which one is closer to the truth based on the simulation results
				\item Paper II: Use the resulting completely observed data, introduce random missing data, and show how the ordinal affinity score method performs on ordinal variables compared with other method	. Assess the performance of the ordinal affinity score method because we know the true values of the completely observed data
			\end{coi}
	\end{coi}	
		

\section*{Order}
	\begin{coi}
		\item Rework theory, design frames/questionnaire
		\item Pre-test
		\item New IRB approval
		\item Pre-analysis plan and pre-registration
		\item Field experiment
		\item Analysis of the results
	\end{coi}


\section*{Rework theory, design frames/questionnaire}
	\begin{coi}
		\item I have sent Liz an email with my current framing chapter and the questionnaire from the previous experiment. I recall that she had various input on the chapter setup, the experiment design, and the questionnaire, so I thought it best to start out from these documents. She emailed back with general instructions to sharpen up the theoretical part. I then researched the literature, and we had a Zoom call on June 23. The main change from that talk is that I will juxtapose moral frames (i.e. values) with self-interest frames. This is more precise and clear-cut than the vague `amoral' frame category that we can't be sure even exists
		\item After researching and reading a lot, I emailed Liz again with the following design idea. She signed off on it. It's not a major change. I basically only adds a moderator as a further nuance:
			\begin{coi}
				\item Moral conviction literature tells us that people with moralized attitudes hold those attitudes strongly. I take from this that these people's attitudes can't be moved, no matter what opposing or supporting moral or self-interest frames we give them. We can only move the attitudes of people who don't hold highly moralized attitudes, since there is room for movement here
				\item I thus suggest to separate respondents into those who hold moralized attitudes on an issue and those who don't. To do so, I would first give all respondents descriptions of what `moral' is and what `self-interest' is, for instance: ``Moral concerns what people should or should not do etc." and ``Self-interest concerns actions and attitudes that only suit yourself etc." (obviously I need to flesh these out much more). I will take the `moral' description directly from Ryan. He essentially took Skitka's moral conviction measure (below) and added the `moral' description. I will take that and further add the `self-interest' description
				\item I would then use Tim Ryan's version of Skitka's moral conviction measure (asking respondents ``To what extent is your position on [issue] a reflection of your core moral beliefs and convictions" and ``... connected to your fundamental beliefs about right and wrong?") -- with the tweak that I don't ask them about their position on the issue, but about their attitude towards the issue overall. Let's say that the issue is abortion. I give respondents the descriptions of `moral' and `self-interest'. I then ask them: ``To what extent is your position on abortion a reflection of your core moral beliefs and convictions" and ``To what extent is your position on abortion connected to your fundamental beliefs about right and wrong?" -- but without actually asking them about their position yet (basically leaving that open until they get the frame). The alternative is that I ask them about their position on abortion twice. I would here (1) ask them where they stand on abortion on 1-5 Likert, (2) give them the descriptions, (3) measure moral conviction, (4) randomly assign a frame, (5) ask them where they stand on abortion on 1-5 Likert again. The big problem with that is anchoring. Liz agrees with my approach. While it's better to have people write down their stands (more concrete for them and also allows me to be more precise in my analyses), the downside effect of anchoring is a pretty big (too big) downside
				\item After I measure moral conviction on their attitude towards the issue (1-5 Likert; ``Not at all", ``Slightly", ``Moderately", ``Much", ``Very much"), every respondent randomly gets one of the five frames: opposing moral frame, opposing self-interest frame, control frame, supporting moral frame, supporting self-interest frame. Every respondent then registers his support/opposition to the issue on another 1-5 Likert scale (``Strongly oppose" ... ``Strongly approve")
				\item For the respondents with highly moralized attitudes on the issue, their support/opposition for the issue should be statistically the same across all frames -- since their attitudes are set and can't easily be moved. For the respondents without highly moralized attitudes on the issue, the frames should move responses towards support or opposition, depending on the direction of the frame. For these people, we can see whether the moral or the self-interest frames cause bigger shifts. I would expect moral frames to cause bigger shifts for highly moralized, since moral arguments likely fall on fertile ground here. For low moralized, I would expect self-interest frames to cause bigger shifts, since these people reject the importance of morals for the issue
				\item Insights that I can see:
					\begin{coi}
						\item We can test which issues are considered more moral than others 
						\item We can test whether people with highly moralized attitudes really stick to their pre-formed attitudes, no matter what they're exposed to 
						\item We can test whether people with low moralization are more influenced by moral or self-interest frames 
						\item We can test whether people with no moralization are most influenced by arguments based on self-interest 
					\end{coi}
			\end{coi}
		\item Reorganize chapter outline
		\item Expand framing section
			\begin{coi}
				\item Outline differences between equivalency and emphasis frames (I'm looking at emphasis)
				\item Outline differences between emphasis frames and new information (Leeper \& Slothuus)
				\item Clearly express that we do know why frames work (Zaller: Frames move persuasive information to the top of one's mind) but that we don't know why some frames are successful at moving persuasive information to the top of one's mind and others aren't. This was not initially clear to Liz
			\end{coi}
		\item Set up section on morality from the literature
			\begin{coi}
				\item Incorporate Stoker on public opinion in the public sphere (i.e. her stuff on ethics)
				\item Is there theorizing on ``value frames" or ``moral frames" (Stoker, Google Scholar)?
				\item Jamie's article he sent me
				\item Chris Wolsko
				\item Willer and Feinberg (how they used MFT)
				\item I need a description of `morality`. I can take that from Tim Ryan
				\item I need criteria along which I can construct the frames. For morals or values, Moral Foundations Theory is an option. Liz has also written about this in her diss. I'm not sure whether to go with MFT, since it's so party-ID based, though
				\item Feldman chapter in the Oxford Handbook of Political Psychology (some time around 2016 or so) -- gives a more complete overview of the field
				\item Kinder on the ``primary ingredients" of public opinion (one of which is ``matters of principle"), Feldman on values, Milton Rokeach on values
			\end{coi}
		\item Set up section self-interest from the literature
			\begin{coi}
				\item Look at the paper I wrote for Liz' class for works on self-interest
				\item I need a description of `self-interest'
				\item I need criteria along which I can construct the frames
			\end{coi}
		\item Choose issues based on the literature and what works for perceived self-interest
		\item Design issue frames built on morals and self-interest
			\begin{coi}
				\item Do I use stuff from MFQ?
			\end{coi}
		\item Connect everything up coherently
		\item Send it to everyone for feedback
		\item Email Lucid to arrange experiment to be run before the end of the year
		\item Morals
			\begin{coi}
				\item Leave out moral conviction, it just complicates things because conviction and MFT don't play well together $\rightarrow$ DONE
				\item Play down the language on Haidt a bit. He exaggerates the differences between parties. There is nothing sacred about pid in Haidt, the values are what matters. He just shows that Dems and Reps differ on average with respect to the foundations, i.e. not all Dems have the Dem pattern and vice versa $\rightarrow$ DONE
				\item As I talk about moral vs. nonmoral issues, make sure to mention that I'm about moral and self-interest frames, not the issues. Don't get lost in the issue discussion, so that readers won't think I'm mainly about the issues $\rightarrow$ DONE
				\item Fix disjuncture between theory and design: I say that moral frames work because people have emotional attachments to their morals/values/whatever, but then I posit that moral frames work among people without moral conviction. Why would morals influence people who don't seem to have morals? $\rightarrow$ DONE
				\item Forget about pid, just ask people about their moral preferences, the same way I ask about their self-interest tax burdens (directionality, where you stand). Measure self-interest, measure moral foundations for each respondent (i.e. query where they stand on the particular moral foundation) -- use parts of MFQ $\rightarrow$ DONE
				\item Find moral frames that appeal to all (or most) people. Fasten on some moral foundations that I think map best to each of the two issues $\rightarrow$ DONE
			\end{coi}
		\item Self-interest
			\begin{coi}
				\item Kinder is one of the doubters that self-interest matters all that much. Make sure I only cite him that way $\rightarrow$ DONE
				\item Do Campbell, Converse, Miller, and Stokes really say self-interest is the main driver of political opinion? -- They don't. Delete that reference $\rightarrow$ DONE
				\item Political psychologists who talk about self-interest are definitely not rational choices. Don't put everyone on this topic into the rat choice rat hole. Self-interest is not automatically part of rat choice $\rightarrow$ DONE
				\item Move away from material self-interest. Material self-interest is not the same thing as self-interest. Don't limit my study to that, since I'm biasing my findings against self-interest right out of the gate. This narrow understanding of self-interest is precisely why researchers have found little evidence of it in public opinion $\rightarrow$ DONE
				\item Leave out perceived self-interest (i.e. not make it a major thing) $\rightarrow$ DONE
				\item Define self-interest as related to personal autonomy, health/safety, wealth, and status (Weeden and Kurzban, evolutionary psychology). No need to include family well-being (that's too far for my purposes). Example of ``non-material" but obvious self-interest: Young guys who oppose hawkish Presidents because they don't want to be drafted are acting in their self-interest. Women of child bearing age who want to be free from the possibility of an unwanted pregnancy may support abortion rights out of self-interest $\rightarrow$ DONE
				\item Set up competing self-interests that people have (e.g. everyone wants low taxes, everybody wants to be healthy) $\rightarrow$ DONE
			\end{coi}
		\item Frames
			\begin{coi}
				\item Move away from the whole ``move to the top of people's minds" thing. That's priming, not framing, and it doesn't fit my theoretical setup. I'm doing strong and weak frames, particularly whether moral or self-interest frames are more likely to compel people to change a specific attitude. The term ``frame" comes from the idea of framing a picture. If you were to photograph a scene, you might choose to include some details and exclude others and, when you do so, that changes the way people will interpret the scene $\rightarrow$ DONE
				\item Move away from ``more important in shaping political attitudes". My chapter focuses on ``what makes a strong frame", with the assertion that ``strong frames are moral frames". A chapter focusing on ``what is more important in people's attitude formation, morals or self-interest?" is too general of a question and also has been looked at by others. Make sure it's specifically about the juxtaposition of moral vs. self-interest in frames, not in general $\rightarrow$ DONE
				\item Engage more with Druckman and Chong (2007) since they differentiate weak from strong frames $\rightarrow$ Druckman and Chong (APSR, 2007) ask respondents in a pre-test what arguments they consider strong or weak for the issues they chose. Druckman and Chong then assert that frames containing arguments deemed strong are strong frames and frames containing arguments deemed weak are weak frames. They then use these strong and weak frames in their actual experiment. They let people decide pre-experiment what they consider strong, which doesn't give any insights as to what actually makes a frame strong. We just know which are considered strong and weak, but not why $\rightarrow$ DONE
				\item 5 frames per issue $\rightarrow$ DONE
				\item Find one other issue. Ditch taxes for ... national security, infrastructure (something where self-interest and moral frames are each roughly equally strong). For healthcare: Healthcare costs and health insurance costs  may be very different things (p. 83). I may love paying \$0 for insurance, but hate that my out-of-pocket expenses are enormous. Make sure I consistently stick to one and don't mix them up $\rightarrow$ DONE
				\item My frames are not actually frames, since I'm describing different policies. To build stimuli appropriate for testing my theory, I need to keep the content (scene) the same across the various treatment groups but change what implications are emphasized, e.g. a low cost health care plan might save tax payer money or harm poor people. Set up a policy with some meat on it, something more substantial that is the same across treatment groups $\rightarrow$ DONE
				\item Make frames a bit longer in terms of sentences. Have them read articles, bigger things, longer, more, not just one sentence $\rightarrow$ DONE
			\end{coi}
		\item Miscellaneous
			\begin{coi}
				\item Palin example needs to go -- that's providing new (mis)information, not a frame $\rightarrow$ DONE
				\item Cite literature to back up content in the introduction $\rightarrow$ DONE
				\item I say in the introduction that morals have supplanted self-interest over time and recently. It sounds like I'm asserting that, when I'm actually just referring to what scholars are saying. Be more explicit and back it up, e.g.: Scholars suggest that morals have supplanted self-interest over time. Frank (2004), Haidt (2012) and several others argue that morals are more important now $\rightarrow$ DONE
			\end{coi}
		\item Send chapter to Liz
		\item Questionnaire
			\begin{coi}
				\item Healthcare $\rightarrow$ DONE
					\begin{coi}
						\item Single-payer, tax-based, universal, pay healthcare by taxes, government hired the companies -- too direct, too detailed, take that out. ``Improving healthcare in the US", ``paid through a mix of individual and employer fees", keep everything much more vague, not many details so as not to put anyone off
						\item Moral supporting: ``Affordable healthcare for everyone" -- that's self-interest. Find some form of ``this doesn't help/hurt you, but it will help poor/elderly people"
						\item Moral opposing: Vulnerable/Elderly people will get substandard care, long lines, no appointments etc.
						\item Self-interest supporting is good
						\item Self-interest opposing: The typical person needs to pay more (move away from the autonomy of decisions here)
					\end{coi}
				\item Environment $\rightarrow$ DONE
					\begin{coi}
						\item Don't use climate change, stay with some kind of environmental restrictions/regulations, e.g. preventing companies from dumping chemicals into the water, something like that. But phrase it as generally as possible so as not to trigger anyone
						\item Moral supporting restrictions: Poor people are harmed by companies without regulations
						\item Moral opposing restrictions: Difficult for people to comply with regulations, poor people might lose their job when companies need to pay more. The people who deforest need money from logging, with restrictions they don't have any income any more. Same for fisheries
						\item Self-interest supporting restrictions: Otherwise we might get cancer and die
						\item Self-interest opposing restrictions: Restrictions costs money, you will pay more for products
					\end{coi}
				\item ``How much does Care/Harm and how much does self-interest matter to you?" -- I do that very well with the MFQ questions. Now I need to get a self-interest scale comparable to the MFQs that estimates, overall, how selfish (i.e. self-interested) a person is (WITHOUT asking about each issue, just asking in general) $\rightarrow$ DONE
				\item shiny
					\begin{coi}
						\item Remove the last question about the code as it may deter people from completing since Lucid gives everyone an RID value when they complete $\rightarrow$ DONE
						\item Do multiple attention checks in different formats (apparently important for Lucid). From Ryan: \href{https://www.qualtrics.com/blog/using-attention-checks-in-your-surveys-may-harm-data-quality/}{Qualtrics}, \href{https://onlinelibrary.wiley.com/doi/10.1111/ajps.12396}{Wiley} $\rightarrow$ DONE
						\item Set up that each respondent randomly sees (and gets blocked on) either ordered probit or ANES $\rightarrow$ DONE
						\item After speaking with Jeff and Ryan, here is the final setup: I split the sample into ANES and probit categories. Each respondent randomly gets one or the other. I save the assigned data for each set in separate folders. Probit respondents are in /seqblock.op, ANES respondents are in /seqblock.an. So I get two datasets per issue. I assign treatment for the issues independently, i.e. respondents are not assigned to the same treatment group for both issues. I speed things up a bit by incorporating observeEvent() into eventReactive() when treatment is assigned. That eliminates the additional download I had before. I block only on education (so I took pid out)
					\end{coi}					
				\item Safe-guarding against file-write traffic jam
					\begin{coi}
						\item I have tested it simultaneously on two laptops. When one laptop is accessing Dropox, the other simply waits, then accesses Dropbox itself. There is no error or other conflict. That means if 50 people click it at the same time, the 50th person would have a 1-minute lag. It's not ideal but not a big problem
						\item I added one sentence in brackets to the assignment pages that it might take a bit for the code to load and that they please not quite the browser
					\end{coi}
				\item Final adjustments
					\begin{coi}
						\item Go through Liz' .pdf with comments
						\item Include the words ``environment" and ``healthcare" in each of the issue's information section
						\item Read through each frame carefully and try to make sure they are similar in terms of (a) length, and (b) oomph (i.e.``strength")
					\end{coi}
				\item Work in committee feedback
					\begin{coi}
						\item Ryan: Take out ``Permanently disabled" as an employment group
						\item Liz (and Jeff): Insert some throw-away questions at the start of the survey (so that things don't start off with the heavy psych stuff), e.g.``For how long have you been using the Mechanical Turk service?", ``For how long have you been answering surveys with Lucid?", ``How interested are you typically in the studies you take part in?"
						\item Liz: Create a separate page introduction to the psych batteries to prepare people for what is to come, e.g. ``Next, we'd like to ask you some questions about your social views and how you see yourself"  -- I also added separate introduction pages before the demographics and before the issues
						\item Liz: Create a bold title (like a newspaper headline) for the treatment pages so that people know what this is and what I'm asking of them, i.e. ``Potential new healthcare plan introduced". Above that, in italics, write something like ``Please read the following text carefully and answer the questions that follow"
						\item Ryan: Overall, if possible, try out font sizes, bolding to make things more visually pleasing -- I discovered that you can adjust a few things by setting the type to HTML. I added a nice logo, spaced everything out a bit more nicely, put any comments to respondents in italics, and made the bullet points nicer
					\end{coi}
			\end{coi}
	\end{coi}
	

\section*{Get new IRB approval}

\vspace{0.4cm}

\section*{Pre-test}
	\begin{coi}
		\item Set pre-test up according to Liz' emails
		\item Liz:
			\begin{coi}
				\item She said to basically just test the experiment survey before the experiment. A sort of mini-experiment, to see if the patterns emerge as they should (i.e. we don't see effects that reverse my hypotheses), just with fewer people
				\item If something is off, I can then adjust things. Ideally, I would then test them again, but nothing is perfect. One pre-test is still better than none
				\item She recommends \$0.50 per respondent, so that's 240 overall
			\end{coi}
		\item I don't want to have two separate surveys. If I make changes in one, I have to manually adjust the other, and that will just lead to differences in the end. Instead, I set up the survey to run for MTurk and Lucid with if()-statements. I made the following tweaks:
			\begin{coi}
				\item For Lucid, education samples probit or ANES. For MTurk, education only samples the probit categories. Otherwise the small sample would get split up even further. And the blocking comparison between the two sets is useless for this amount of respondents anyway
				\item For Lucid, the code reads in the RID, saves it, and uses it for the redirect at the end. For MTurk, the RID and the redirect don't matter
				\item For Lucid, respondents get code.txt without a unique code at the end. They also get a Continue button, since they need to be redirected in Lucid's sytem. For MTurk, respondents get code.mturk.txt with a unique survey code without a Continue button
				\item Following Liz' suggestion, I added a comment box page before the code page so people can tell me if they thought something was problematic (``If you have any comments for the researcher, please share them here")
				\item Originally, the code saved all data when people hit Continue on the last page. That doesn't work now since MTurk people don't have a Continue. I thus moved the data saving to the comments page for both platforms
				\item MTurk people need to see the unique code on the last page, but the survey needs to save that code beforehand (since they can't hit Continue on that page). Originally, the unique code was created inside code.mturk.txt in reactive() code, so it was created on the page that people saw. That doesn't work any more. To work around that, I now create and save the unique code with normal R before the shiny code starts. Then I simply save that object together with all the survey input on the comments page and insert it inside createPage() for the code page. That way I can save the unique code and MTurk people can see it on the last code page to then copy-paste into the MTurk browser window
			\end{coi}
		\item Code checks
			\begin{coi}
				\item (Be INCREDIBLY careful with any randomization of response options. Many things in the code use the corresponding number for respondents' response selections, not the actual words, so messing with the order is a very delicate thing)
				\item Set platform to MTurk
				\item Do 200 trials, then see that everything was blocked properly for both sets of education categories (i.e. check that in R and on Dropbox)
				\item Are the education categories blocked like I want?
				\item Are all the responses being saved to Dropbox like I want?
				\item Are the correct .txt files shown in the survey depending on the group I'm being blocked into?
				\item Do all the treatment group .txt files contain the correct corresponding frames?
				\item Are the apostrophes working?
				\item Are the words ``environment" and ``healthcare" in each frame setup (for the checks)?
				\item Any typos anywhere?
			\end{coi}
		\item Final tasks before launch
			\begin{coi}
				\item Delete everything in all /alldata and /seqblock folders online 
				\item Delete everything in all /alldata folders and all seqblock files on my machine
				\item Re-deploy app
			\end{coi}			
	\end{coi}

\section*{Analyze pre-test results}
	\begin{coi}
		\item How do the groups look?
		\item Which frames got more support than which others?
		\item Do any results look weird?
		\item Any helpful comments?
		\item I rejected everyone who failed any of the three attention checks (one pre-treatment on numbers/letters, two post-treatment factual ones) and reassigned those tasks. It took 7 batches, but I now have 240 responses who passed all tests
		\item However: After I had done this, Liz told me that I should not exclude people who failed the two post-treatment checks. Something about treatment affecting passage rates and the failed checks potentially showing something other than lacking attentiveness, e.g. that my treatments were difficult for people to understand. I get the first, sort of, but I don't believe the second
		\item Regardless I now have one analysis for all the people who passed (the 7 batches) and one analysis for all the people who passed the first check (only from batch 1), both in \texttt{pre.test.analysis.R}
	\end{coi}

\section*{Set up pre-registration on OSF (from RT2 training)}
	\begin{coi}
		\item Created account
		\item Filled in all the details
		\item Note: Just because you have a pre-analysis plan doesn't mean that's all you can do with your data (and it doesn't mean exploratory analysis is now forbidden). If there is a good theoretical motivation that you can defend, then you can do that
	\end{coi}

\section*{Experiment}
	\begin{coi}
		\item Power analysis
			\begin{coi}
				\item Do a power analysis to be see that I have a chance to detect typical framing effects. There is an R function for that, use that (\texttt{DeclareDesign})
				\item DeclareDesign is super complex, so I asked Jeff and Ryan for help. Ryan couldn't help me too much, but I can try to experiment with the stuff \href{https://declaredesign.org/r/fabricatr/articles/variable_generation.html}{here} and see whether that gets me anywhere (though I doubt it)
				\item I'm leaving this be. It's super complex and requires tons of assumptions to begin with anyway. Besides, I will run the experiment no matter the any power analysis results, and I have plenty of respondents
			\end{coi}
		\item Lucid attention checks
			\begin{coi}
				\item Lucid can redirect people who fail the check, then the survey will stop, the people will be removed, and I don't have to pay for them
				\item Something that has come up in the pre-test: Since I throw out people who fail the attention checks post-test, those people are all part of the blocking data. I block on 300 people but only analyze 200, in general terms. Nothing I can do here with MTurk, but since Lucid can terminate people during the survey, this comes into play
				\item Following what Liz said about not excluding people based on the post-treatment checks (see above), I added a terminating redirect for anyone who doesn't select option 2 for the first (numbers/letters) check. Those guys won't see the rest of the survey, won't be blocked, and won't be part of the saved data
			\end{coi}
		\item Pre-registration
			\begin{coi}
				\item Update questionnaire .pdf to reflect final shiny version
				\item Upload questionnaire to pre-registration and look through my entries again
				\item Publish pre-registration
			\end{coi}
		\item Code checks (less extensive than before and set to Lucid)
			\begin{coi}
				\item Re-deploy app
				\item Are the redirects working on my end?
			\end{coi}
		\item Final tasks before launch
			\begin{coi}
				\item Set platform to Lucid
				\item Re-deploy app if needed
				\item Delete everything in all /alldata and /seqblock folders online 
				\item Delete everything in all /alldata folders and all seqblock files on my machine
			\end{coi}
		\item We did a soft launch with 50 people. The code worked as it should, and we only got people who passed the attention check, meaning the redirect worked as well. I authorized the full launch			
	\end{coi}
	
\section*{Analyze substantive results}
	\begin{coi}
		\item Most straightforward is to use the method I use to block
		\item But I also have lots of good resources how to analyze ordinal variables as DVs, instead of turning them into intervals for a normal regression, including a Bayesian way
		\item Brad Jones feedback from a while ago: ``A key part of the argument that I was trying to make in my dissertation was that the effect of different frames would be differentially felt conditional on respondents' own moral priorities (measured with the moral foundations questionnaire). So, a sanctity framing only would affect someone's opinion if they were scored particularly highly on the sanctity dimension of the MFQ. For someone who doesn't get worked up by sanctity, they wouldn't be expected to react to the frame (or even consider it a moral/ethical framing)
		\item Select figure/tables (what do I use, what goes in the appendix) and write up text
	\end{coi}
	
\section*{Add missing data with all my tested methods and compare results}
	\begin{coi}
		\item I did the same analyses that I did in the ordinal missing chapter. 5 variables NA for ANES and OP, MAR and MNAR. Then the same again for 10 variables each
		\item Write up results
	\end{coi}


\section*{Crispify writing}
	\begin{coi}
		\item If I want to mention my pre-registration in the paper, I can quote articles in the BITSS /readings folder. My pre-registration link is \href{https://osf.io/tvpwq/}{https://osf.io/tvpwq/}
		\item Expand discussion of the limitations and problems with using MTurk for social research a bit, use \begin{verbatim} @huff_who_2015; @clifford_2015_samples; @stritch_2017_opportunities; 
			@burnham_2018_mturk \end{verbatim} (all already downloaded)
		\item Expand discussion of limitations and problems with using Lucid for social research a bit as well, use \begin{verbatim} @coppock_2019_validating \end{verbatim}
		\item Talk about the pre-/post-treatment attention checks and whether post-treatment checks should be used to throw out/disregard people. This came up after the pre-test and before the experiment. Liz said there is the possibility that the treatment might somehow influence passage rates and that variation in how people respond to the check could have substantive meaning beyond just attention (e.g. maybe one of the treatments was difficult for people to understand). Ryan and Liz recommended Montgomery, Nyhan, Torres (2018) (I have the pdf in /non-probability\_surveys)
		\item Add a few lines that I added a factual manipulation check (treatment-independent), \begin{verbatim} @kane_2019_harm \end{verbatim}
		\item Top of p. 80:  See Jim Gibson, and others, add stuff on procedures vs outcomes
		\item 4.2, middle of p. 82: See Brooks and Manza here on public opinion and welfare state support (since I'll use healthcare, especially)
		\item First paragraph p. 74: Use Rokeach (his book from the 1960s) for a more intuitive description of what it means to be moral, i.e. values as ``oughts" and ``shoulds". Either switch Skitka's (1), (2), (3) for Rokeach or say that Skitka says that people FEEL it's an objective truth (not that she's actually stating that morals are objective truths)
		\item Second paragraph p. 74: This part meanders around, goes back and forth between issues and arguments/frames. Restructure it, make my point more clearly, it's a bit muddied and hard to follow now
		\item There is a short article by Haidt that provides numerical means for liberals and conservatives. Include those numbers where I talk about the foundations. Don't use numbers for each foundation, use averages for all the conservative ones and the liberal ones. We want to have some idea of the effect sizes for the ideological differences for the foundations, something we can measure. Also add some more language that the distinctions Haidt makes are all tendencies, not more
		\item Weeden and Kurzban: Dial it back a little, be less of a fan boy. I went too much to the other side. Present the other side more, the one I had too much of before (the one where self-interest is financial). Present both sides, then say which side I fall on. Also avoid first person when I talk about the side I fall on
		\item Include argument why I choose environment as my second issue
	\end{coi}


\section*{Final write-up}
	\begin{coi}
		\item Write conclusion
	\end{coi}

\section*{Pre-defense feedback Liz}
	\begin{coi}
		\item p. 69, first paragraph: Add that the manipulated message is often not intentionally manipulated
		\item p. 69, 70: Combine the two paragraphs into one. Make everything about moral vs. self-interest, leave out the stuff about frame strength
		\item p. 74, sentence ``Appeals to values/morals ...": This kind of looks like we already know that moral frames work better than non-moral frames. ("Appeals" might look a lot like frames.) Clarify the weaknesses of this work and/or how what you do is different/better
		\item p. 79, first paragraph: This paragraph reads as though you agree with all of these claims, whereas I think in some cases you are reporting the authors' claims but do not agree yourself. Please rephrase slightly to indicate those places where you are simply reporting authors' claims
		\item p. 80, middle paragraph: Important additional point I would make as an emotions scholar: self-interest ALSO invokes emotion. You might briefly mention this, mainly as a caveat to the widespread assumption that "self-interest" is somehow just cognitive. You can cite Richard Lazarus' book Emotion \& Adaptation. He argues that emotions are evoked WHENEVER a person's goals are advanced or threatened. Those goals could be value-based, but they could also be self-interested
		\item p. 82, middle paragraph: But, given Haidt's emphasis, you should at least probe PID, e.g., as a possible moderator
		\item p. 82, bottom paragraph: Based on suitability to assess self-interest AND morality
		\item p. 88, middle paragraph: Explain why blocking, and blocking on education specifically, is important here
		\item p. 89, sentence ``Identifying as a Democrat ...": Wording here confusing - sounds like you are describing an interaction
		\item Table 4.2: I don't think you explicitly mentioned above that each substantive frame will be contrasted with the control. Also, I think you have yet to explain what was in the control frame?
		\item Table 4.2: Explain why it was important to include control variables in an experiment. (Improves precision.) Many argue controls are not needed in large N experiments because of the magic of random assignment
		\item Bottom of p. 91: I find all the acronyms get in the way of understanding, esp. because we need to keep track of education blocking and frame acronyms. Consider spelling out for the frames?
		\item Bottom of p. 91: Remove decimals for ``35.000" and ``67.000"
		\item Bottom of p. 91: Reduce ``1.770" and ``2.780" to one decimal
		\item Bottom of p. 103: Mention focus on care/harm
		\item Top of p. 104: Early on, you say you are only looking at ATEs, but you are also looking at conditional average treatment effects
		\item p. 105, final paragraph: Again, clarify this is about care/harm specifically (these high scorers may not be "moral" on all dimensions)
		\item Table 4.3: It is more usual to determine "high" and "low" according to how many people fall into the categories. E.g., top 1/3 vs. bottom 1/3, or top 1/2 vs. bottom 1/2. This is very lopsided. I would suggest a re-do with at least somewhat more similar sized buckets. When using a measurement scale as a moderator, it is typical to define "high" and "low" based on the sample distribution, not the measurement scale. My current preference is to take the top-third and bottom-third of the distribution (leaving one-third as neither high nor low but "middle"). I think this makes sense substantively. Your current way of doing things would be interpreted by some as using arbitrary cut-offs. In addition, you have a practical problem in the high morality analysis of a small fraction who are defined as "low." The second analysis is more balanced, as you note, but the total N is different, which confused me and seemed not ideal. Using (comparable) parts of the sample for both is better
		\item Run some quick analyses looking for differences by party ID, given that Dems are more oriented toward care and also, as you note, that the parties may even conceive of care differently. I personally like subgroup analyses. This would entail just re-running exactly what you've already done (for the ATEs only) twice more: once with Dems and one with Reps. Or, you could insert PID interactions with the treatment. These analyses are suitable for an appendix, especially if you don't find any major differences
	\end{coi}


\section*{Pre-defense feedback Jeff}
	\begin{coi}
		\item Page 71: "One example is Tversky \& Kahneman (1981)'s death and survival experiment (see chapter 2)". Use the LaTeX \begin{verbatim}\pageref\end{verbatim} system to identify the page
		\item Page 74: "(i.e. moral-" sticks into the right margin. There's a LaTeX setting to make hyponation "tighter" or "looser"
		\item General: I feel like the discussion needs some more sub-headings (subsection) to identify the parts of the discussion better
		\item PAGE 88: define SATEs
		\item Tables 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8: put "0"s before "."s
		\item Figures 4.1 and 4.2 would benefit from some color
		\item Page 100: There's a big whitespace at the top from the previous table. Use something like \begin{verbatim}\vspace{-1in}\end{verbatim}
	\end{coi}










\end{document}
